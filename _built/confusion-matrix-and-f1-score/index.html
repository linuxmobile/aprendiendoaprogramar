<!doctype html><html domain=.com lang=en><meta charset=utf-8><meta content="width=device-width,initial-scale=1" name=viewport><meta content="" http-equiv=Content-Security-Policy><link href=/favicon.svg rel=icon type=image/svg+xml><meta content=#f9c412 name=theme-color><meta content="max-snippet:-1, max-image-preview: large, max-video-preview: -1" name=robots><title>Confusion matrix & f1-score | Note of Thi</title><meta content="Confusion matrix & f1-score | Note of Thi" prefix=og:http://ogp.me/ns# property=og:title><meta content="Confusion matrix actual (yes) actual (no) predict (yes) TP FP predict (no) FN TN True Positive (TP): what we predict Positive is really..." name=description><meta content="Confusion matrix actual (yes) actual (no) predict (yes) TP FP predict (no) FN TN True Positive (TP): what we predict Positive is really..." prefix=og:http://ogp.me/ns# property=og:description><meta content=summary_large_image name=twitter:card><meta content=@dinhanhthi name=twitter:site><meta content=@dinhanhthi name=twitter:creator><meta content=https://dinhanhthi.com/img_src/cover.png prefix=og:http://ogp.me/ns# property=og:image><meta content=article prefix=og:http://ogp.me/ns# property=og:type><link href=https://dinhanhthi.com/confusion-matrix-and-f1-score/ rel=canonical><meta content=https://dinhanhthi.com/confusion-matrix-and-f1-score/ prefix=og:http://ogp.me/ns# property=og:url><meta content=no-referrer-when-downgrade name=referrer><link href=/feed/feed.xml rel=alternate type=application/atom+xml title="ðŸ”¥ Anh-Thi DINH"><link href=/ rel=preconnect crossorigin><link href=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.css rel=stylesheet crossorigin=anonymous integrity=sha384-zTROYFVGOfTw7JV7KUu8udsvW2fx4lWOsCEDqhBreBwlHI4ioVRtmIvEThzJHGET><script src=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.js defer crossorigin=anonymous integrity=sha384-GxNFqL3r9uRJQhR+47eDxuPoNE7yLftQM8LcxzgS4HT73tp970WS/wV5p8UzCOmb></script><script src=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/contrib/auto-render.min.js defer crossorigin=anonymous integrity=sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl onload=renderMathInElement(document.body);></script><style>body {
      visibility: hidden;
      opacity: 0;
    }</style><noscript><style>body {
        visibility: visible;
        opacity: 1;
      }</style></noscript><script csp-hash>if (/Mac OS X/.test(navigator.userAgent))
      document
        .documentElement
        .classList
        .add('apple')</script><link href=/src/css/main.css rel=stylesheet type=text/css><style>@font-face{font-display:swap;font-family:'fontello';src:url(/fontello/font/fontello.eot?46432155);src:url(/fontello/font/fontello.eot?46432155#iefix) format('embedded-opentype'),url(/fontello/font/fontello.woff2?46432155) format('woff2'),url(/fontello/font/fontello.woff?46432155) format('woff'),url(/fontello/font/fontello.ttf?46432155) format('truetype'),url(/fontello/font/fontello.svg?46432155#fontello) format('svg');font-weight:400;font-style:normal}[class*=" icon-"]:before,[class^=icon-]:before{font-family:"fontello";font-style:normal;font-weight:400;speak:never;display:inline-block;text-decoration:inherit;width:1em;margin-right:.2em;text-align:center;font-variant:normal;text-transform:none;line-height:1em;margin-left:.2em;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}.icon-doc:before{content:'\e800'}.icon-doc-add:before{content:'\e801'}.icon-stats:before{content:'\e802'}.icon-tags:before{content:'\e803'}.icon-like:before{content:'\e804'}.icon-cog-alt:before{content:'\e805'}.icon-project:before{content:'\e806'}.icon-mooc:before{content:'\e807'}.icon-dl:before{content:'\e808'}.icon-ml:before{content:'\e809'}.icon-python:before{content:'\e80a'}.icon-nlp:before{content:'\e80b'}.icon-r-lang:before{content:'\e80c'}.icon-skill:before{content:'\e80d'}.icon-js-solid:before{content:'\e80e'}.icon-game:before{content:'\e80f'}.icon-web:before{content:'\e810'}.icon-algo:before{content:'\e811'}.icon-mooc-solid:before{content:'\e812'}.icon-chatbot:before{content:'\e813'}.icon-web-dev:before{content:'\e814'}.icon-data:before{content:'\e815'}.icon-skill-solid:before{content:'\e816'}.icon-python-solid:before{content:'\e817'}.icon-project-solid:before{content:'\e818'}.icon-js:before{content:'\e819'}.icon-rocket:before{content:'\e81a'}.icon-ml-solid:before{content:'\e81b'}.icon-game-solid:before{content:'\e81c'}.icon-dl-solid:before{content:'\e81d'}.icon-nlp-solid:before{content:'\e81e'}.icon-web-solid:before{content:'\e81f'}.icon-algo-solid:before{content:'\e820'}.icon-puzzle-outline:before{content:'\e821'}.icon-ng:before{content:'\e822'}.icon-ok:before{content:'\e823'}.icon-link:before{content:'\e824'}.icon-down-circle:before{content:'\e826'}.icon-api:before{content:'\e828'}.icon-right-circle:before{content:'\e829'}.icon-down-open:before{content:'\e82a'}.icon-right-open:before{content:'\e82b'}.icon-copy:before{content:'\f0c5'}.icon-gamepad:before{content:'\f11b'}.icon-fork:before{content:'\f126'}.icon-mlops-solid:before{content:'\f135'}.icon-edu-solid:before{content:'\f19d'}.icon-others-solid:before{content:'\f1b3'}.icon-ds-solid:before{content:'\f1c0'}.icon-chart-area:before{content:'\f1fe'}.icon-chart-pie:before{content:'\f200'}.icon-ts:before{content:'\f201'}.icon-clone:before{content:'\f24d'}</style><body><script>function showTheme() {
        const btn = document.getElementById("toggle-dark-light");
        let toggleIcon = btn.firstElementChild;
        const currentTheme = localStorage.getItem("theme");
        if (currentTheme === "dark") {
          document
            .body
            .classList
            .toggle("dark-theme");
          toggleIcon.src = "/img_src/nav/sun.svg";
        } else if (currentTheme === "light") {
          document
            .body
            .classList
            .toggle("light-theme");
          toggleIcon.src = "/img_src/nav/moon.svg";
        }
      }
      function showContent() {
        document.body.style.visibility = 'visible';
        document.body.style.opacity = 1;
      }
      window.addEventListener('DOMContentLoaded', (event) => {
        showTheme();
        showContent();
      });</script><header class="wave-border wave-border-post"><nav><div id=nav><a href=/ class="nav-item no-effect"><img alt=home class=keep-original src=/img_src/nav/home.svg height=18 width=18> <span>Thi</span> </a><a href=/about/ class="nav-item no-effect"><img alt=about class=keep-original src=/img_src/nav/about.svg height=15 width=15> <span>About</span></a><div class=nav-search id=nav-search><form><input aria-label='search notes (press "/" to focus & "ESC" to lose)' autocomplete=off class=nav-search__input id=nav-search__input onfocusin=inFocus(this) placeholder='search notes (press "/" to focus & "ESC" to lose)' type=search></form><div id=nav-search__result-container style="display: none;"><ul id=nav-search__ul></ul><div id=nav-search__no-result style="display: none;"><p>No results found.</div></div></div><span class="nav-item no-effect nav-dark-light" href="" id=toggle-dark-light><img alt=light-mode class=keep-original src=/img_src/nav/moon.svg height=20 width=20> </span><a href=https://github.com/dinhanhthi class="nav-item no-effect nav-github" target=_blank><img alt=github class=keep-original src=/img_src/nav/github.svg height=20 width=20></a></div><div class=reading-progress-container><div id=reading-progress aria-hidden=true></div></div></nav><script>var divNavSearch=document.getElementById("nav-search"),divRes=document.getElementById("nav-search__result-container"),ulRes=document.getElementById("nav-search__ul");function inFocus(e){""!=e.value&&(divRes.style.display="block")}var isOnDiv=!1;divRes.addEventListener("mouseover",(function(){isOnDiv=!0})),divRes.addEventListener("mouseout",(function(){isOnDiv=!1}));var inputSearch=document.getElementById("nav-search__input");window.addEventListener("click",(function(){ulRes.getElementsByTagName("li").length>=1&&isOnDiv||(divRes.style.display="none")})),inputSearch.addEventListener("click",(e=>{e.stopPropagation()}));const addSelected=e=>{ulRes.querySelectorAll("li").forEach((e=>{e.classList.remove("selected")})),e.classList.add("selected")};var isInView=(e,t)=>{var n=e.offsetTop+e.offsetHeight-t.scrollTop>t.offsetHeight;return e.offsetTop<t.scrollTop?"above":n?"below":"in"};const updateScroll=(e,t)=>{e.offsetTop+e.offsetHeight-t.scrollTop>t.offsetHeight&&(t.scrollTop=e.offsetTop+e.offsetHeight-t.offsetHeight),e.offsetTop<t.scrollTop&&(t.scrollTop=e.offsetTop)};document.onkeydown=e=>{checkInInput=document.activeElement==inputSearch,"/"!==e.key||checkInInput||(e.stopPropagation(),e.preventDefault(),inputSearch.focus())},document.addEventListener("focusin",(e=>{divNavSearch.contains(e.target)||(divRes.style.display="none")})),inputSearch.onkeydown=e=>{if("Enter"===e.key){e.stopPropagation(),e.preventDefault();var t=ulRes.querySelector('li[class*="selected"]');window.location.href=t.getElementsByClassName("item__content")[0].firstChild.firstChild.href}"Escape"===e.key&&(divRes.style.display="none",inputSearch.blur())},divNavSearch.onkeydown=e=>{if(hasResult=ulRes.getElementsByTagName("li").length>=1,hasResult){["ArrowUp","ArrowDown"].indexOf(e.key)>-1&&e.preventDefault();var t=ulRes.firstChild,n=ulRes.lastChild,s=ulRes.querySelector('li[class*="selected"]');switch(e.key){case"ArrowUp":nextLi=s&&s!=t?s.previousSibling:n,addSelected(nextLi),s=nextLi,updateScroll(s,divRes);break;case"ArrowDown":nextLi=s&&s!=n?s.nextSibling:t,addSelected(nextLi),s=nextLi,updateScroll(s,divRes)}}};</script><div class=header-container><div class="header-logo post-layout"><img alt="Confusion matrix & f1-score" class=keep-original src=/img/cats/ml.svg height=55 width=55></div><h1>Confusion matrix & f1-score</h1><div id=more-info><div id=note-tag><a href=/tags/machine-learning/ id=category }>Machine Learning</a></div><div id=last-modified>Last modified 2 years ago / <a href=https://github.com/dinhanhthi/notes/edit/master/./posts/ml/2019-05-25-confusion-matrix-and-f1-score.md>Edit on Github</a></div></div></div></header><main class="" id=main-wrapper><article class=post-container><div class="container mt-2 normal page-note"><div class="danger not-full-warning"><div class=warning-icon><img alt=Warning class=keep-original src=/img_src/icons/time.svg></div><div>This post was <strong>updated more than 1 year ago</strong>, some information may be outdated!</div></div><div class="toc toc-common toc-js"><div class=ol-container><div class=toc-heading>In this note</div><ol><li><a href=#confusion-matrix>Confusion matrix</a><ol><li><a href=#how-to-remember%3F>How to remember?</a><li><a href=#type-i-%2F-type-ii-errors>Type I / Type II errors</a><li><a href=#why-cm-is-important%3F>Why CM is important?</a></ol><li><a href=#precision-%26-recall>Precision & Recall</a><ol><li><a href=#when-to-use%3F>When to use?</a><li><a href=#precision_recall_curve>Precision / Recall curve</a></ol><li><a href=#f1-score>F1-Score</a><ol><li><a href=#when-to-use-f1-score%3F>When to use F1-Score?</a><li><a href=#how-to-choose-f1-score-value%3F>How to choose f1-score value?</a></ol><li><a href=#accuracy-%2F-specificity>Accuracy / Specificity</a><ol><li><a href=#when-to-use%3F-1>When to use?</a></ol><li><a href=#the-roc-curve>The ROC Curve</a><ol><li><a href=#the-auc>The AUC</a></ol><li><a href=#confusion-matrix-%26-f1-score-with-scikit-learn>Confusion Matrix & F1-Score with Scikit-learn</a><li><a href=#references>References</a></ol></div></div><h2 id=confusion-matrix tabindex=-1>Confusion matrix <a href=#confusion-matrix class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h2><table><thead><tr><th style=text-align:center><th style=text-align:center>actual (yes)<th style=text-align:center>actual (no)<tbody><tr><td style=text-align:center>predict (yes)<td style=text-align:center><span class=tgreen-light>TP</span><td style=text-align:center><span class=tpink-light>FP</span><tr><td style=text-align:center>predict (no)<td style=text-align:center><span class=tpink-light>FN</span><td style=text-align:center><span class=tgreen-light>TN</span></table><div class=columns-2 markdown=1><div markdown=1><ul><li><strong>True Positive</strong> (<strong class=tgreen>TP</strong>): what we predict Positive is really Positive.<li><strong>True Negative</strong> (<strong class=tgreen>FN</strong>): what we predict Negative is really Negative.<li><strong>False Negative</strong> (<strong>FN</strong>): what we predict Negative is actually Positive.<li><strong>False Positive</strong> (<strong>FP</strong>): what we predict Positive is actually Negative.</ul></div><p><img alt="This guy is pregnant?" class="img-full-100 pop" src=/img/post/ML/confusion-matrix-f1-score/cm_ex.png><br><em>This guy is pregnant?</em></div><h3 id=how-to-remember%3F tabindex=-1>How to remember? <a href=#how-to-remember%3F class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h3><ul><li><strong>True</strong>/<strong>False</strong> indicates what we predicted is right/wrong.<li><strong>Positive</strong>/<strong>Negative</strong> is what we predicted (yes or no).</ul><h3 id=type-i-%2F-type-ii-errors tabindex=-1>Type I / Type II errors <a href=#type-i-%2F-type-ii-errors class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h3><ul><li>FP = <a href=https://en.wikipedia.org/wiki/Type_I_and_type_II_errors>Type I</a> error = rejection of true null hypothesis = negative results are predicted wrongly = what we predict positive is actually negative.<li>FN = <a href=https://en.wikipedia.org/wiki/Type_I_and_type_II_errors>Type II</a> error = non-rejection of a false null hypothesis = positive results are predicted wrongly = what we predict negative are actually positive.</ul><h3 id=why-cm-is-important%3F tabindex=-1>Why CM is important? <a href=#why-cm-is-important%3F class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h3><p>Give a general view about our model, "is it really good?" thanks to precision and recall!<h2 id=precision-%26-recall tabindex=-1>Precision & Recall <a href=#precision-%26-recall class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h2><p class=table.bd-right.table-dark><table><thead><tr><th style=text-align:center><th style=text-align:center>actual (yes)<th style=text-align:center>actual (no)<th style=text-align:center><tbody><tr><td style=text-align:center>predict (yes)<td style=text-align:center><span class=tgreen-light>TP</span><td style=text-align:center><span class=tpink-light>FP</span><td style=text-align:center><strong>Precision</strong><tr><td style=text-align:center>predict (no)<td style=text-align:center><span class=tpink-light>FN</span><td style=text-align:center><span class=tgreen-light>TN</span><td style=text-align:center><tr><td style=text-align:center><td style=text-align:center><strong>Recall</strong><td style=text-align:center><td style=text-align:center></table><ul><li><p><strong>Precision</strong>: How many of our positive predictions are really true? (Check the accuracy of our positive predictions).<section class=eqn><eqn><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mrow><mi mathvariant=normal>p</mi><mi mathvariant=normal>r</mi><mi mathvariant=normal>e</mi><mi mathvariant=normal>c</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>s</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>o</mi><mi mathvariant=normal>n</mi></mrow><mo>=</mo><mfrac><mrow><mi mathvariant=normal>t</mi><mi mathvariant=normal>r</mi><mi mathvariant=normal>u</mi><mi mathvariant=normal>e</mi><mtext>â€‰</mtext><mi mathvariant=normal>p</mi><mi mathvariant=normal>o</mi><mi mathvariant=normal>s</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>t</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>v</mi><mi mathvariant=normal>e</mi></mrow><mrow><mi mathvariant=normal>p</mi><mi mathvariant=normal>o</mi><mi mathvariant=normal>s</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>t</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>v</mi><mi mathvariant=normal>e</mi><mi mathvariant=normal>l</mi><mi mathvariant=normal>y</mi><mtext>â€‰</mtext><mi mathvariant=normal>p</mi><mi mathvariant=normal>r</mi><mi mathvariant=normal>e</mi><mi mathvariant=normal>d</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>c</mi><mi mathvariant=normal>t</mi><mi mathvariant=normal>e</mi><mi mathvariant=normal>d</mi><mtext>â€‰</mtext><mi mathvariant=normal>r</mi><mi mathvariant=normal>e</mi><mi mathvariant=normal>s</mi><mi mathvariant=normal>u</mi><mi mathvariant=normal>l</mi><mi mathvariant=normal>t</mi><mi mathvariant=normal>s</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant=normal>T</mi><mi mathvariant=normal>P</mi></mrow><mrow><mrow><mi mathvariant=normal>T</mi><mi mathvariant=normal>P</mi></mrow><mo>+</mo><mrow><mi mathvariant=normal>F</mi><mi mathvariant=normal>P</mi></mrow></mrow></mfrac><mi mathvariant=normal>.</mi></mrow><annotation encoding=application/x-tex>\mathrm {precision}= \dfrac{\mathrm{true\, positive}}{\mathrm{positively\, predicted\, results}}= \dfrac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FP}}.</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8623em;vertical-align:-0.1944em;></span><span class=mord><span class="mord mathrm">precision</span></span><span class=mspace style=margin-right:0.2778em;></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em;></span></span><span class=base><span class=strut style=height:2.2253em;vertical-align:-0.8804em;></span><span class=mord><span class="nulldelimiter mopen"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3449em;><span style=top:-2.314em;><span class=pstrut style=height:3em;></span><span class=mord><span class=mord><span class="mord mathrm" style=margin-right:0.01389em;>positively</span><span class=mspace style=margin-right:0.1667em;></span><span class="mord mathrm">predicted</span><span class=mspace style=margin-right:0.1667em;></span><span class="mord mathrm">results</span></span></span></span><span style=top:-3.23em;><span class=pstrut style=height:3em;></span><span class=frac-line style=border-bottom-width:0.04em;></span></span><span style=top:-3.677em;><span class=pstrut style=height:3em;></span><span class=mord><span class=mord><span class="mord mathrm">true</span><span class=mspace style=margin-right:0.1667em;></span><span class="mord mathrm">positive</span></span></span></span></span><span class=vlist-s>â€‹</span></span><span class=vlist-r><span class=vlist style=height:0.8804em;><span></span></span></span></span></span><span class="nulldelimiter mclose"></span></span><span class=mspace style=margin-right:0.2778em;></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em;></span></span><span class=base><span class=strut style=height:2.1297em;vertical-align:-0.7693em;></span><span class=mord><span class="nulldelimiter mopen"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3603em;><span style=top:-2.314em;><span class=pstrut style=height:3em;></span><span class=mord><span class=mord><span class="mord mathrm">TP</span></span><span class=mspace style=margin-right:0.2222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em;></span><span class=mord><span class="mord mathrm">FP</span></span></span></span><span style=top:-3.23em;><span class=pstrut style=height:3em;></span><span class=frac-line style=border-bottom-width:0.04em;></span></span><span style=top:-3.677em;><span class=pstrut style=height:3em;></span><span class=mord><span class=mord><span class="mord mathrm">TP</span></span></span></span></span><span class=vlist-s>â€‹</span></span><span class=vlist-r><span class=vlist style=height:0.7693em;><span></span></span></span></span></span><span class="nulldelimiter mclose"></span></span><span class=mord>.</span></span></span></span></span></eqn></section><li><p><strong>Recall</strong>: How many of positive results belong to our predictions? (Do we miss some negative predictions?)<section class=eqn><eqn><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mrow><mi mathvariant=normal>r</mi><mi mathvariant=normal>e</mi><mi mathvariant=normal>c</mi><mi mathvariant=normal>a</mi><mi mathvariant=normal>l</mi><mi mathvariant=normal>l</mi></mrow><mo>=</mo><mfrac><mrow><mi mathvariant=normal>t</mi><mi mathvariant=normal>r</mi><mi mathvariant=normal>u</mi><mi mathvariant=normal>e</mi><mtext>â€‰</mtext><mi mathvariant=normal>p</mi><mi mathvariant=normal>o</mi><mi mathvariant=normal>s</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>t</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>v</mi><mi mathvariant=normal>e</mi></mrow><mrow><mi mathvariant=normal>p</mi><mi mathvariant=normal>o</mi><mi mathvariant=normal>s</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>t</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>v</mi><mi mathvariant=normal>e</mi><mi mathvariant=normal>l</mi><mi mathvariant=normal>y</mi><mtext>â€‰</mtext><mi mathvariant=normal>a</mi><mi mathvariant=normal>c</mi><mi mathvariant=normal>t</mi><mi mathvariant=normal>u</mi><mi mathvariant=normal>a</mi><mi mathvariant=normal>l</mi><mtext>â€‰</mtext><mi mathvariant=normal>r</mi><mi mathvariant=normal>e</mi><mi mathvariant=normal>s</mi><mi mathvariant=normal>u</mi><mi mathvariant=normal>l</mi><mi mathvariant=normal>t</mi><mi mathvariant=normal>s</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant=normal>T</mi><mi mathvariant=normal>P</mi></mrow><mrow><mrow><mi mathvariant=normal>T</mi><mi mathvariant=normal>P</mi></mrow><mo>+</mo><mrow><mi mathvariant=normal>F</mi><mi mathvariant=normal>N</mi></mrow></mrow></mfrac><mi mathvariant=normal>.</mi></mrow><annotation encoding=application/x-tex>\mathrm {recall}= \dfrac{\mathrm{true\, positive}}{\mathrm{positively\, actual\, results}}= \dfrac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FN}}.</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em;></span><span class=mord><span class="mord mathrm">recall</span></span><span class=mspace style=margin-right:0.2778em;></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em;></span></span><span class=base><span class=strut style=height:2.2253em;vertical-align:-0.8804em;></span><span class=mord><span class="nulldelimiter mopen"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3449em;><span style=top:-2.314em;><span class=pstrut style=height:3em;></span><span class=mord><span class=mord><span class="mord mathrm" style=margin-right:0.01389em;>positively</span><span class=mspace style=margin-right:0.1667em;></span><span class="mord mathrm">actual</span><span class=mspace style=margin-right:0.1667em;></span><span class="mord mathrm">results</span></span></span></span><span style=top:-3.23em;><span class=pstrut style=height:3em;></span><span class=frac-line style=border-bottom-width:0.04em;></span></span><span style=top:-3.677em;><span class=pstrut style=height:3em;></span><span class=mord><span class=mord><span class="mord mathrm">true</span><span class=mspace style=margin-right:0.1667em;></span><span class="mord mathrm">positive</span></span></span></span></span><span class=vlist-s>â€‹</span></span><span class=vlist-r><span class=vlist style=height:0.8804em;><span></span></span></span></span></span><span class="nulldelimiter mclose"></span></span><span class=mspace style=margin-right:0.2778em;></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em;></span></span><span class=base><span class=strut style=height:2.1297em;vertical-align:-0.7693em;></span><span class=mord><span class="nulldelimiter mopen"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3603em;><span style=top:-2.314em;><span class=pstrut style=height:3em;></span><span class=mord><span class=mord><span class="mord mathrm">TP</span></span><span class=mspace style=margin-right:0.2222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em;></span><span class=mord><span class="mord mathrm">FN</span></span></span></span><span style=top:-3.23em;><span class=pstrut style=height:3em;></span><span class=frac-line style=border-bottom-width:0.04em;></span></span><span style=top:-3.677em;><span class=pstrut style=height:3em;></span><span class=mord><span class=mord><span class="mord mathrm">TP</span></span></span></span></span><span class=vlist-s>â€‹</span></span><span class=vlist-r><span class=vlist style=height:0.7693em;><span></span></span></span></span></span><span class="nulldelimiter mclose"></span></span><span class=mord>.</span></span></span></span></span></eqn></section></ul><p><img alt="An example of using confusion matrix" class=img-85 src=/img/post/ML/confusion-matrix-f1-score/confusion-matrix-example.png><br><em>Recognizing number 5. Figure taken from <a href=https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ >this book</a>.</em><h3 id=when-to-use%3F tabindex=-1>When to use? <a href=#when-to-use%3F class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h3><ul><li><strong>Precision</strong> is importantly used when the "wrongly predicted yes" (FP) influences much (e.g. <em>This email is spam?</em> -- results yes but actually no and we lost important emails!).<li><strong>Recall</strong> (<em><strong>Sensitivity</strong></em>) is importantly used when the "wrongly predicted no" (FN) influences much (e.g. In the banking industry, <em>this transaction is fraudulent?</em> -- results no but actually yes and we lost money!).</ul><h3 id=precision_recall_curve tabindex=-1>Precision / Recall curve <a href=#precision_recall_curve class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h3><p>With <em>thresholds</em>, we can use <code>precision_recall_curve()</code> to compute precision and recall for all possible thresholds,<p><img alt="An example of Precision/Recall curve" class=img-85 src=/img/post/ML/confusion-matrix-f1-score/precision-reacll-curve.png><br><em>An example of Precision/Recall curve with many thresholds. Figure taken from <a href=https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ >this book</a>.</em><p><strong>Trace-off</strong>: Higher precision, lower recall and vice versa.<pre class=language-python><code class=language-python><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> precision_recall_curve<br>precisions<span class="token punctuation">,</span> recalls<span class="token punctuation">,</span> thresholds <span class="token operator">=</span> precision_recall_curve<span class="token punctuation">(</span>y_train_5<span class="token punctuation">,</span> y_scores<span class="token punctuation">)</span><br><br>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>thresholds<span class="token punctuation">,</span> precisions<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"b--"</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"Precision"</span><span class="token punctuation">)</span><br>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>thresholds<span class="token punctuation">,</span> recalls<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"g-"</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"Recall"</span><span class="token punctuation">)</span><br>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><h2 id=f1-score tabindex=-1>F1-Score <a href=#f1-score class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h2><p>High precision and low recall or vice versa? F1-Score gives us a balance between precision and recall.<section class=eqn><eqn><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>f</mi><mn>1</mn></msub><mo>=</mo><msup><mrow><mo fence=true>(</mo><mfrac><mrow><msup><mrow><mi mathvariant=normal>r</mi><mi mathvariant=normal>e</mi><mi mathvariant=normal>c</mi><mi mathvariant=normal>a</mi><mi mathvariant=normal>l</mi><mi mathvariant=normal>l</mi></mrow><mrow><mo>âˆ’</mo><mn>1</mn></mrow></msup><mo>+</mo><msup><mrow><mi mathvariant=normal>p</mi><mi mathvariant=normal>r</mi><mi mathvariant=normal>e</mi><mi mathvariant=normal>c</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>s</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>o</mi><mi mathvariant=normal>n</mi></mrow><mrow><mo>âˆ’</mo><mn>1</mn></mrow></msup></mrow><mn>2</mn></mfrac><mo fence=true>)</mo></mrow><mrow><mo>âˆ’</mo><mn>1</mn></mrow></msup><mo>=</mo><mn>2</mn><mo>Ã—</mo><mfrac><mrow><mrow><mi mathvariant=normal>p</mi><mi mathvariant=normal>r</mi><mi mathvariant=normal>e</mi><mi mathvariant=normal>c</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>s</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>o</mi><mi mathvariant=normal>n</mi></mrow><mo>â‹…</mo><mrow><mi mathvariant=normal>r</mi><mi mathvariant=normal>e</mi><mi mathvariant=normal>c</mi><mi mathvariant=normal>a</mi><mi mathvariant=normal>l</mi><mi mathvariant=normal>l</mi></mrow></mrow><mrow><mrow><mi mathvariant=normal>p</mi><mi mathvariant=normal>r</mi><mi mathvariant=normal>e</mi><mi mathvariant=normal>c</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>s</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>o</mi><mi mathvariant=normal>n</mi></mrow><mo>+</mo><mrow><mi mathvariant=normal>r</mi><mi mathvariant=normal>e</mi><mi mathvariant=normal>c</mi><mi mathvariant=normal>a</mi><mi mathvariant=normal>l</mi><mi mathvariant=normal>l</mi></mrow></mrow></mfrac><mi mathvariant=normal>.</mi></mrow><annotation encoding=application/x-tex>f_1 = \left({\frac {\mathrm {recall} ^{-1}+\mathrm {precision} ^{-1}}{2}}\right)^{-1}=2\times {\frac {\mathrm {precision} \cdot \mathrm {recall} }{\mathrm {precision} +\mathrm {recall} }}.</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em;></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em;>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em;><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;><span class=pstrut style=height:2.7em;></span><span class="mtight reset-size6 size3 sizing"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>â€‹</span></span><span class=vlist-r><span class=vlist style=height:0.15em;><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em;></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em;></span></span><span class=base><span class=strut style=height:2.7295em;vertical-align:-0.95em;></span><span class=minner><span class=minner><span class="mopen delimcenter" style=top:0em;><span class="size3 delimsizing">(</span></span><span class=mord><span class=mord><span class="nulldelimiter mopen"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.5754em;><span style=top:-2.314em;><span class=pstrut style=height:3em;></span><span class=mord><span class=mord>2</span></span></span><span style=top:-3.23em;><span class=pstrut style=height:3em;></span><span class=frac-line style=border-bottom-width:0.04em;></span></span><span style=top:-3.677em;><span class=pstrut style=height:3em;></span><span class=mord><span class=mord><span class=mord><span class="mord mathrm">recall</span></span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8984em;><span style=top:-3.1473em;margin-right:0.05em;><span class=pstrut style=height:2.7em;></span><span class="mtight reset-size6 size3 sizing"><span class="mord mtight"><span class="mord mtight">âˆ’</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em;></span><span class=mord><span class=mord><span class="mord mathrm">precision</span></span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8719em;><span style=top:-3.1208em;margin-right:0.05em;><span class=pstrut style=height:2.7em;></span><span class="mtight reset-size6 size3 sizing"><span class="mord mtight"><span class="mord mtight">âˆ’</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s>â€‹</span></span><span class=vlist-r><span class=vlist style=height:0.686em;><span></span></span></span></span></span><span class="nulldelimiter mclose"></span></span></span><span class="mclose delimcenter" style=top:0em;><span class="size3 delimsizing">)</span></span></span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:1.7795em;><span style=top:-4.0283em;margin-right:0.05em;><span class=pstrut style=height:2.7em;></span><span class="mtight reset-size6 size3 sizing"><span class="mord mtight"><span class="mord mtight">âˆ’</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em;></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em;></span></span><span class=base><span class=strut style=height:0.7278em;vertical-align:-0.0833em;></span><span class=mord>2</span><span class=mspace style=margin-right:0.2222em;></span><span class=mbin>Ã—</span><span class=mspace style=margin-right:0.2222em;></span></span><span class=base><span class=strut style=height:2.2519em;vertical-align:-0.8804em;></span><span class=mord><span class=mord><span class="nulldelimiter mopen"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3714em;><span style=top:-2.314em;><span class=pstrut style=height:3em;></span><span class=mord><span class=mord><span class="mord mathrm">precision</span></span><span class=mspace style=margin-right:0.2222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em;></span><span class=mord><span class="mord mathrm">recall</span></span></span></span><span style=top:-3.23em;><span class=pstrut style=height:3em;></span><span class=frac-line style=border-bottom-width:0.04em;></span></span><span style=top:-3.677em;><span class=pstrut style=height:3em;></span><span class=mord><span class=mord><span class="mord mathrm">precision</span></span><span class=mspace style=margin-right:0.2222em;></span><span class=mbin>â‹…</span><span class=mspace style=margin-right:0.2222em;></span><span class=mord><span class="mord mathrm">recall</span></span></span></span></span><span class=vlist-s>â€‹</span></span><span class=vlist-r><span class=vlist style=height:0.8804em;><span></span></span></span></span></span><span class="nulldelimiter mclose"></span></span></span><span class=mord>.</span></span></span></span></span></eqn></section><p>F1-score depends on how we label the class "positive". <em>This email is spam?</em> is <strong>very different</strong> from <em>This email is not spam?</em><h3 id=when-to-use-f1-score%3F tabindex=-1>When to use F1-Score? <a href=#when-to-use-f1-score%3F class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h3><ul><li>When you need a balance between precision and recall.<li>When we have a "skewed class" problem (uneven class distribution, too many "yes" and very few "no", for example).<li>One of precision and recall is improved but the other changes too much, then f1-score will be very small!</ul><h3 id=how-to-choose-f1-score-value%3F tabindex=-1>How to choose f1-score value? <a href=#how-to-choose-f1-score-value%3F class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h3><p>Normally, <span class=eq><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>f</mi><mn>1</mn></msub><mo>âˆˆ</mo><mo stretchy=false>(</mo><mn>0</mn><mo separator=true>,</mo><mn>1</mn><mo stretchy=false>]</mo></mrow><annotation encoding=application/x-tex>f_1\in (0,1]</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em;></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em;>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em;><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;><span class=pstrut style=height:2.7em;></span><span class="mtight reset-size6 size3 sizing"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>â€‹</span></span><span class=vlist-r><span class=vlist style=height:0.15em;><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em;></span><span class=mrel>âˆˆ</span><span class=mspace style=margin-right:0.2778em;></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em;></span><span class=mopen>(</span><span class=mord>0</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em;></span><span class=mord>1</span><span class=mclose>]</span></span></span></span></span> and it gets the higher values, the better our model is.<ul><li>The best one (<span class=eq><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>f</mi><mn>1</mn></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding=application/x-tex>f_1=1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em;></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em;>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em;><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;><span class=pstrut style=height:2.7em;></span><span class="mtight reset-size6 size3 sizing"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>â€‹</span></span><span class=vlist-r><span class=vlist style=height:0.15em;><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em;></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em;></span></span><span class=base><span class=strut style=height:0.6444em;></span><span class=mord>1</span></span></span></span></span>), both precision and recall get <span class=eq><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mn>100</mn><mi mathvariant=normal>%</mi></mrow><annotation encoding=application/x-tex>100\%</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8056em;vertical-align:-0.0556em;></span><span class=mord>100%</span></span></span></span></span>.<li>One of precision and recall gets very small value (close to 0), <span class=eq><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>f</mi><mn>1</mn></msub></mrow><annotation encoding=application/x-tex>f_1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em;></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em;>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em;><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;><span class=pstrut style=height:2.7em;></span><span class="mtight reset-size6 size3 sizing"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>â€‹</span></span><span class=vlist-r><span class=vlist style=height:0.15em;><span></span></span></span></span></span></span></span></span></span></span> is very small, our model is not good!</ul><p>What if we prefer one of precision and recall than the other? We consider <span class=eq><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>f</mi><mi>Î²</mi></msub></mrow><annotation encoding=application/x-tex>f_{\beta}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.9805em;vertical-align:-0.2861em;></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em;>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em;><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;><span class=pstrut style=height:2.7em;></span><span class="mtight reset-size6 size3 sizing"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.05278em;>Î²</span></span></span></span></span><span class=vlist-s>â€‹</span></span><span class=vlist-r><span class=vlist style=height:0.2861em;><span></span></span></span></span></span></span></span></span></span></span><sup><a href=https://pdfs.semanticscholar.org/3dcd/a1bec36586b46b1dc67a477beca2c5a105be.pdf target=_blank rel="noopener noreferrer">[ref]</a></sup><section class=eqn><eqn><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>f</mi><mi>Î²</mi></msub><mo>=</mo><mo stretchy=false>(</mo><mn>1</mn><mo>+</mo><msup><mi>Î²</mi><mn>2</mn></msup><mo stretchy=false>)</mo><mfrac><mrow><mtext>precision</mtext><mo>â‹…</mo><mtext>recall</mtext></mrow><mrow><msup><mi>Î²</mi><mn>2</mn></msup><mo>â‹…</mo><mtext>precision</mtext><mo>+</mo><mtext>recall</mtext></mrow></mfrac></mrow><annotation encoding=application/x-tex>f_{\beta} = ( 1 + \beta^2)\frac{\text{precision}\cdot\text{recall}}{\beta^2\cdot\text{precision} + \text{recall}}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.9805em;vertical-align:-0.2861em;></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em;>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em;><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;><span class=pstrut style=height:2.7em;></span><span class="mtight reset-size6 size3 sizing"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.05278em;>Î²</span></span></span></span></span><span class=vlist-s>â€‹</span></span><span class=vlist-r><span class=vlist style=height:0.2861em;><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em;></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em;></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em;></span><span class=mopen>(</span><span class=mord>1</span><span class=mspace style=margin-right:0.2222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em;></span></span><span class=base><span class=strut style=height:2.2519em;vertical-align:-0.8804em;></span><span class=mord><span class="mord mathnormal" style=margin-right:0.05278em;>Î²</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8641em;><span style=top:-3.113em;margin-right:0.05em;><span class=pstrut style=height:2.7em;></span><span class="mtight reset-size6 size3 sizing"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class=mclose>)</span><span class=mord><span class="nulldelimiter mopen"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3714em;><span style=top:-2.314em;><span class=pstrut style=height:3em;></span><span class=mord><span class=mord><span class="mord mathnormal" style=margin-right:0.05278em;>Î²</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.7401em;><span style=top:-2.989em;margin-right:0.05em;><span class=pstrut style=height:2.7em;></span><span class="mtight reset-size6 size3 sizing"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em;></span><span class=mbin>â‹…</span><span class=mspace style=margin-right:0.2222em;></span><span class="mord text"><span class=mord>precision</span></span><span class=mspace style=margin-right:0.2222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em;></span><span class="mord text"><span class=mord>recall</span></span></span></span><span style=top:-3.23em;><span class=pstrut style=height:3em;></span><span class=frac-line style=border-bottom-width:0.04em;></span></span><span style=top:-3.677em;><span class=pstrut style=height:3em;></span><span class=mord><span class="mord text"><span class=mord>precision</span></span><span class=mspace style=margin-right:0.2222em;></span><span class=mbin>â‹…</span><span class=mspace style=margin-right:0.2222em;></span><span class="mord text"><span class=mord>recall</span></span></span></span></span><span class=vlist-s>â€‹</span></span><span class=vlist-r><span class=vlist style=height:0.8804em;><span></span></span></span></span></span><span class="nulldelimiter mclose"></span></span></span></span></span></span></eqn></section><p><span class=eq><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>f</mi><mn>1</mn></msub></mrow><annotation encoding=application/x-tex>f_1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em;></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em;>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em;><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;><span class=pstrut style=height:2.7em;></span><span class="mtight reset-size6 size3 sizing"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>â€‹</span></span><span class=vlist-r><span class=vlist style=height:0.15em;><span></span></span></span></span></span></span></span></span></span></span> is a special case of <span class=eq><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>f</mi><mi>Î²</mi></msub></mrow><annotation encoding=application/x-tex>f_{\beta}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.9805em;vertical-align:-0.2861em;></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em;>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em;><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;><span class=pstrut style=height:2.7em;></span><span class="mtight reset-size6 size3 sizing"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.05278em;>Î²</span></span></span></span></span><span class=vlist-s>â€‹</span></span><span class=vlist-r><span class=vlist style=height:0.2861em;><span></span></span></span></span></span></span></span></span></span></span> when <span class=eq><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>Î²</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding=application/x-tex>\beta=1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em;></span><span class="mord mathnormal" style=margin-right:0.05278em;>Î²</span><span class=mspace style=margin-right:0.2778em;></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em;></span></span><span class=base><span class=strut style=height:0.6444em;></span><span class=mord>1</span></span></span></span></span>:<ul><li>When precision is more important than recall, we choose <span class=eq><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>Î²</mi><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding=application/x-tex>\beta &lt; 1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em;></span><span class="mord mathnormal" style=margin-right:0.05278em;>Î²</span><span class=mspace style=margin-right:0.2778em;></span><span class=mrel>&lt;</span><span class=mspace style=margin-right:0.2778em;></span></span><span class=base><span class=strut style=height:0.6444em;></span><span class=mord>1</span></span></span></span></span> (usually choose <span class=eq><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>Î²</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding=application/x-tex>\beta=0.5</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em;></span><span class="mord mathnormal" style=margin-right:0.05278em;>Î²</span><span class=mspace style=margin-right:0.2778em;></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em;></span></span><span class=base><span class=strut style=height:0.6444em;></span><span class=mord>0.5</span></span></span></span></span>).<li>When recall is more important than precision, we choose <span class=eq><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>Î²</mi><mo>></mo><mn>1</mn></mrow><annotation encoding=application/x-tex>\beta > 1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em;></span><span class="mord mathnormal" style=margin-right:0.05278em;>Î²</span><span class=mspace style=margin-right:0.2778em;></span><span class=mrel>></span><span class=mspace style=margin-right:0.2778em;></span></span><span class=base><span class=strut style=height:0.6444em;></span><span class=mord>1</span></span></span></span></span> (usually choose <span class=eq><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>Î²</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding=application/x-tex>\beta=2</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em;></span><span class="mord mathnormal" style=margin-right:0.05278em;>Î²</span><span class=mspace style=margin-right:0.2778em;></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em;></span></span><span class=base><span class=strut style=height:0.6444em;></span><span class=mord>2</span></span></span></span></span>).</ul><h2 id=accuracy-%2F-specificity tabindex=-1>Accuracy / Specificity <a href=#accuracy-%2F-specificity class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h2><ul><li><p><strong>Accuracy</strong>: How accurate our predictions to the whole predictions?<section class=eqn><eqn><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mrow><mi mathvariant=normal>a</mi><mi mathvariant=normal>c</mi><mi mathvariant=normal>c</mi><mi mathvariant=normal>u</mi><mi mathvariant=normal>r</mi><mi mathvariant=normal>a</mi><mi mathvariant=normal>c</mi><mi mathvariant=normal>y</mi></mrow><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding=application/x-tex>\mathrm{accuracy} = \dfrac{TP + TN}{TP + TN + FP + FN}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em;></span><span class=mord><span class="mord mathrm" style=margin-right:0.01389em;>accuracy</span></span><span class=mspace style=margin-right:0.2778em;></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em;></span></span><span class=base><span class=strut style=height:2.1297em;vertical-align:-0.7693em;></span><span class=mord><span class="nulldelimiter mopen"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3603em;><span style=top:-2.314em;><span class=pstrut style=height:3em;></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em;>TP</span><span class=mspace style=margin-right:0.2222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em;></span><span class="mord mathnormal" style=margin-right:0.10903em;>TN</span><span class=mspace style=margin-right:0.2222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em;></span><span class="mord mathnormal" style=margin-right:0.13889em;>FP</span><span class=mspace style=margin-right:0.2222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em;></span><span class="mord mathnormal" style=margin-right:0.10903em;>FN</span></span></span><span style=top:-3.23em;><span class=pstrut style=height:3em;></span><span class=frac-line style=border-bottom-width:0.04em;></span></span><span style=top:-3.677em;><span class=pstrut style=height:3em;></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em;>TP</span><span class=mspace style=margin-right:0.2222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em;></span><span class="mord mathnormal" style=margin-right:0.10903em;>TN</span></span></span></span><span class=vlist-s>â€‹</span></span><span class=vlist-r><span class=vlist style=height:0.7693em;><span></span></span></span></span></span><span class="nulldelimiter mclose"></span></span></span></span></span></span></eqn></section><li><p><strong>Specificity</strong>: How many negative results belong to our predictions?<section class=eqn><eqn><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mrow><mi mathvariant=normal>s</mi><mi mathvariant=normal>p</mi><mi mathvariant=normal>e</mi><mi mathvariant=normal>c</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>f</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>c</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>t</mi><mi mathvariant=normal>y</mi></mrow><mo>=</mo><mfrac><mrow><mi>T</mi><mi>N</mi></mrow><mrow><mi>F</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding=application/x-tex>\mathrm{specificity} = \dfrac{TN}{FP + TN}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em;></span><span class=mord><span class="mord mathrm" style=margin-right:0.01389em;>specificity</span></span><span class=mspace style=margin-right:0.2778em;></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em;></span></span><span class=base><span class=strut style=height:2.1297em;vertical-align:-0.7693em;></span><span class=mord><span class="nulldelimiter mopen"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3603em;><span style=top:-2.314em;><span class=pstrut style=height:3em;></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em;>FP</span><span class=mspace style=margin-right:0.2222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em;></span><span class="mord mathnormal" style=margin-right:0.10903em;>TN</span></span></span><span style=top:-3.23em;><span class=pstrut style=height:3em;></span><span class=frac-line style=border-bottom-width:0.04em;></span></span><span style=top:-3.677em;><span class=pstrut style=height:3em;></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10903em;>TN</span></span></span></span><span class=vlist-s>â€‹</span></span><span class=vlist-r><span class=vlist style=height:0.7693em;><span></span></span></span></span></span><span class="nulldelimiter mclose"></span></span></span></span></span></span></eqn></section></ul><h3 id=when-to-use%3F-1 tabindex=-1>When to use? <a href=#when-to-use%3F-1 class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h3><ul><li><strong>Accuaracy</strong> is used when we have symmetric datasets.<li><strong>Specificity</strong> is used when we care about TN values and don't want to make false alarms of the FP values (e.g. drug test).</ul><h2 id=the-roc-curve tabindex=-1>The ROC Curve <a href=#the-roc-curve class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h2><ul><li>ROC = <em>Receiver operating characteristic</em>.<li>A common tool used with <em>binary classifier</em>.<li>Diffrent from <a href=#precision_recall_curve>precision/recall curve</a>, ROC plots the <em>true positive rate</em> (<em>recall</em>) against the <em>false positive rate</em> (<em>1 - specificity</em>).</ul><p><img alt="An example of ROC curve" class=img-85 src=/img/post/ML/confusion-matrix-f1-score/roc-curve.png><br><em>This ROC curve plots FPR vs TPR for all possible thresholds. <strong>The dotted line</strong> represents the ROC curve of a purely random classifier; a good classifier stays as far away from that lines as possible (<mark>toward the top-left corner</mark>). Figure taken from <a href=https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ >this book</a>.</em><p><strong>Trade-off</strong>: the higher recall, the more FPR (predict wrong) the classifier produces.<pre class=language-python><code class=language-python><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> roc_curve<br><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<br><span class="token operator">%</span>matplotlib inline<br><br>fpr<span class="token punctuation">,</span> tpr<span class="token punctuation">,</span> thresholds <span class="token operator">=</span> roc_curve<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred_prob<span class="token punctuation">)</span><br><span class="token comment"># create plot</span><br>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>fpr<span class="token punctuation">,</span> tpr<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'ROC curve'</span><span class="token punctuation">)</span><br>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'k--'</span><span class="token punctuation">)</span> <span class="token comment"># Dashed diagonal</span><br>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><h3 id=the-auc tabindex=-1>The AUC <a href=#the-auc class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h3><ul><li>AUC = Area under the curve.<li>Perfect classifier will have AUC = 1 (fix the rectangle).<li>The purely random classifier (dotted line) will have AUC = 0.5.</ul><h2 id=confusion-matrix-%26-f1-score-with-scikit-learn tabindex=-1>Confusion Matrix & F1-Score with Scikit-learn <a href=#confusion-matrix-%26-f1-score-with-scikit-learn class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h2><pre class=language-python><code class=language-python><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> confusion_matrix<br>n_classes <span class="token operator">=</span> target<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><br>confusion_matrix<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">,</span> labels<span class="token operator">=</span><span class="token builtin">range</span><span class="token punctuation">(</span>n_classes<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>Precision / Reacall / f1-score / support<pre class=language-python><code class=language-python><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> classification_report<br>classification_report<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span></code></pre><h2 id=references tabindex=-1>References <a href=#references class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h2><ol><li><a href=https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall target=_blank>Classification: Precision and Recall</a> - <strong>Google Developers</strong>, <em>Machine Learning Crash Course</em>.<li><a href=https://developers.google.com/machine-learning/crash-course/classification/check-your-understanding-accuracy-precision-recall target=_blank>Classification: Check Your Understanding (Accuracy, Precision, Recall)</a> - <strong>Google Developers</strong>, <em>Machine Learning Crash Course</em>.<li><a href=https://nlpers.blogspot.com/2007/10/f-measure-versus-accuracy.html target=_blank>F-measure versus Accuracy</a> - <strong>NLP blog</strong>.<li><a href=https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9 target=_blank>Accuracy, Precision, Recall or F1?</a> - <strong>Koo Ping Shung</strong>, <em>Towards Data Science</em>.<li><a href=https://www.marcoaltini.com/blog/dealing-with-imbalanced-data-undersampling-oversampling-and-proper-cross-validation# target=_blank>Dealing with Imbalanced data: undersampling, oversampling and proper cross-validation</a> - <strong>Marco Altini</strong>.<li><a href=https://towardsdatascience.com/accuracy-recall-precision-f-score-specificity-which-to-optimize-on-867d3f11124 target=_blank>Accuracy, Recall, Precision, F-Score & Specificity, which to optimize on?</a> - <strong>Salma Ghoneim</strong>, <em>Towards Data Science</em>.</ol></div><script type=application/ld+json>{
        "@context": "https://schema.org",
        "@type": "Article",
        "headline": "Confusion matrix &amp; f1-score",
        "image": [],
        "author": "Anh-Thi DINH",
        "url": "https://dinhanhthi.com/confusion-matrix-and-f1-score/",
        "mainEntityOfPage": "https://dinhanhthi.com/confusion-matrix-and-f1-score/",
        "datePublished": "01-03-2020",
        "dateModified": "2020-03-01",
        "description": "Confusion matrix actual (yes) actual (no) predict (yes) TP FP predict (no) FN TN True Positive (TP): what we predict Positive is really..."
      }</script></article></main><footer><a href=/ target=_blank>Thi Â Â©Â  2022 </a>Â â€¢Â  <a href=/about-the-notes/ >About this site </a>Â â€¢Â  <a href=https://photos.app.goo.gl/9OVEkdTjmtRPg7vC3 target=_blank>My sketches </a>Â â€¢Â  <a href=https://goo.gl/photos/yQXdQws1LLS16x5v5 target=_blank>I cook </a>Â â€¢Â  <a href=/support-thi/ ><img alt="Support Thi" class=keep-original src=/img_src/icons/coffee.svg height=16 width=auto> Support Thi</a></footer><script src=https://cdnjs.cloudflare.com/ajax/libs/elasticlunr/0.9.6/elasticlunr.min.js></script><script src=/src/js/components/clipboard.min.js></script><script src="/src/js/main.min.js?hash=d3b51a19b7" defer async></script><a href=/support-thi/ class="floating-button tooltip" id=buy-me-a-coffee><img alt="Support Thi" class=keep-original src=/img_src/icons/coffee.svg> <span class=tooltiptext>Support Thi</span> </a><button class="floating-button tooltip" id=scroll-top-btn><img alt="Scroll to top" class=keep-original src=/img_src/to-top.webp> <span class=tooltiptext>Top</span></button>