<!doctype html><html domain=.com lang=en><meta charset=utf-8><meta content="width=device-width,initial-scale=1" name=viewport><meta content="" http-equiv=Content-Security-Policy><link href=/favicon.svg rel=icon type=image/svg+xml><meta content=#f9c412 name=theme-color><meta content="max-snippet:-1, max-image-preview: large, max-video-preview: -1" name=robots><title>Docker + GPUs | Note of Thi</title><meta content="Docker + GPUs | Note of Thi" prefix=og:http://ogp.me/ns# property=og:title><meta content="ðŸ‘‰ Note: Docker 101 ðŸ‘‰ Note: Wordpress Docker ðŸ‘‰ Note: Airflow + Kubernetes 101 ðŸ‘‰ Note: Tensorflow extra WSL + Windows ðŸ‘‰ Note: WSL +..." name=description><meta content="ðŸ‘‰ Note: Docker 101 ðŸ‘‰ Note: Wordpress Docker ðŸ‘‰ Note: Airflow + Kubernetes 101 ðŸ‘‰ Note: Tensorflow extra WSL + Windows ðŸ‘‰ Note: WSL +..." prefix=og:http://ogp.me/ns# property=og:description><meta content=summary_large_image name=twitter:card><meta content=@dinhanhthi name=twitter:site><meta content=@dinhanhthi name=twitter:creator><meta content=https://dinhanhthi.com/img_src/cover.png prefix=og:http://ogp.me/ns# property=og:image><meta content=article prefix=og:http://ogp.me/ns# property=og:type><link href=https://dinhanhthi.com/docker-gpu/ rel=canonical><meta content=https://dinhanhthi.com/docker-gpu/ prefix=og:http://ogp.me/ns# property=og:url><meta content=no-referrer-when-downgrade name=referrer><link href=/feed/feed.xml rel=alternate type=application/atom+xml title="ðŸ”¥ Anh-Thi DINH"><link href=/ rel=preconnect crossorigin><style>body {
      visibility: hidden;
      opacity: 0;
    }</style><noscript><style>body {
        visibility: visible;
        opacity: 1;
      }</style></noscript><script csp-hash>if (/Mac OS X/.test(navigator.userAgent))
      document
        .documentElement
        .classList
        .add('apple')</script><link href=/src/css/main.css rel=stylesheet type=text/css><style>@font-face{font-display:swap;font-family:'fontello';src:url(/fontello/font/fontello.eot?46432155);src:url(/fontello/font/fontello.eot?46432155#iefix) format('embedded-opentype'),url(/fontello/font/fontello.woff2?46432155) format('woff2'),url(/fontello/font/fontello.woff?46432155) format('woff'),url(/fontello/font/fontello.ttf?46432155) format('truetype'),url(/fontello/font/fontello.svg?46432155#fontello) format('svg');font-weight:400;font-style:normal}[class*=" icon-"]:before,[class^=icon-]:before{font-family:"fontello";font-style:normal;font-weight:400;speak:never;display:inline-block;text-decoration:inherit;width:1em;margin-right:.2em;text-align:center;font-variant:normal;text-transform:none;line-height:1em;margin-left:.2em;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}.icon-doc:before{content:'\e800'}.icon-doc-add:before{content:'\e801'}.icon-stats:before{content:'\e802'}.icon-tags:before{content:'\e803'}.icon-like:before{content:'\e804'}.icon-cog-alt:before{content:'\e805'}.icon-project:before{content:'\e806'}.icon-mooc:before{content:'\e807'}.icon-dl:before{content:'\e808'}.icon-ml:before{content:'\e809'}.icon-python:before{content:'\e80a'}.icon-nlp:before{content:'\e80b'}.icon-r-lang:before{content:'\e80c'}.icon-skill:before{content:'\e80d'}.icon-js-solid:before{content:'\e80e'}.icon-game:before{content:'\e80f'}.icon-web:before{content:'\e810'}.icon-algo:before{content:'\e811'}.icon-mooc-solid:before{content:'\e812'}.icon-chatbot:before{content:'\e813'}.icon-web-dev:before{content:'\e814'}.icon-data:before{content:'\e815'}.icon-skill-solid:before{content:'\e816'}.icon-python-solid:before{content:'\e817'}.icon-project-solid:before{content:'\e818'}.icon-js:before{content:'\e819'}.icon-rocket:before{content:'\e81a'}.icon-ml-solid:before{content:'\e81b'}.icon-game-solid:before{content:'\e81c'}.icon-dl-solid:before{content:'\e81d'}.icon-nlp-solid:before{content:'\e81e'}.icon-web-solid:before{content:'\e81f'}.icon-algo-solid:before{content:'\e820'}.icon-puzzle-outline:before{content:'\e821'}.icon-ng:before{content:'\e822'}.icon-ok:before{content:'\e823'}.icon-link:before{content:'\e824'}.icon-down-circle:before{content:'\e826'}.icon-api:before{content:'\e828'}.icon-right-circle:before{content:'\e829'}.icon-down-open:before{content:'\e82a'}.icon-right-open:before{content:'\e82b'}.icon-copy:before{content:'\f0c5'}.icon-gamepad:before{content:'\f11b'}.icon-fork:before{content:'\f126'}.icon-mlops-solid:before{content:'\f135'}.icon-edu-solid:before{content:'\f19d'}.icon-others-solid:before{content:'\f1b3'}.icon-ds-solid:before{content:'\f1c0'}.icon-chart-area:before{content:'\f1fe'}.icon-chart-pie:before{content:'\f200'}.icon-ts:before{content:'\f201'}.icon-clone:before{content:'\f24d'}</style><body><script>function showTheme() {
        const btn = document.getElementById("toggle-dark-light");
        let toggleIcon = btn.firstElementChild;
        const currentTheme = localStorage.getItem("theme");
        if (currentTheme === "dark") {
          document
            .body
            .classList
            .toggle("dark-theme");
          toggleIcon.src = "/img_src/nav/sun.svg";
        } else if (currentTheme === "light") {
          document
            .body
            .classList
            .toggle("light-theme");
          toggleIcon.src = "/img_src/nav/moon.svg";
        }
      }
      function showContent() {
        document.body.style.visibility = 'visible';
        document.body.style.opacity = 1;
      }
      window.addEventListener('DOMContentLoaded', (event) => {
        showTheme();
        showContent();
      });</script><header class="wave-border wave-border-post"><nav><div id=nav><a href=/ class="nav-item no-effect"><img alt=home class=keep-original src=/img_src/nav/home.svg height=18 width=18> <span>Thi</span> </a><a href=/about/ class="nav-item no-effect"><img alt=about class=keep-original src=/img_src/nav/about.svg height=15 width=15> <span>About</span></a><div class=nav-search id=nav-search><form><input aria-label='search notes (press "/" to focus & "ESC" to lose)' autocomplete=off class=nav-search__input id=nav-search__input onfocusin=inFocus(this) placeholder='search notes (press "/" to focus & "ESC" to lose)' type=search></form><div id=nav-search__result-container style="display: none;"><ul id=nav-search__ul></ul><div id=nav-search__no-result style="display: none;"><p>No results found.</div></div></div><span class="nav-item no-effect nav-dark-light" href="" id=toggle-dark-light><img alt=light-mode class=keep-original src=/img_src/nav/moon.svg height=20 width=20> </span><a href=https://github.com/dinhanhthi class="nav-item no-effect nav-github" target=_blank><img alt=github class=keep-original src=/img_src/nav/github.svg height=20 width=20></a></div><div class=reading-progress-container><div id=reading-progress aria-hidden=true></div></div></nav><script>var divNavSearch=document.getElementById("nav-search"),divRes=document.getElementById("nav-search__result-container"),ulRes=document.getElementById("nav-search__ul");function inFocus(e){""!=e.value&&(divRes.style.display="block")}var isOnDiv=!1;divRes.addEventListener("mouseover",(function(){isOnDiv=!0})),divRes.addEventListener("mouseout",(function(){isOnDiv=!1}));var inputSearch=document.getElementById("nav-search__input");window.addEventListener("click",(function(){ulRes.getElementsByTagName("li").length>=1&&isOnDiv||(divRes.style.display="none")})),inputSearch.addEventListener("click",(e=>{e.stopPropagation()}));const addSelected=e=>{ulRes.querySelectorAll("li").forEach((e=>{e.classList.remove("selected")})),e.classList.add("selected")};var isInView=(e,t)=>{var n=e.offsetTop+e.offsetHeight-t.scrollTop>t.offsetHeight;return e.offsetTop<t.scrollTop?"above":n?"below":"in"};const updateScroll=(e,t)=>{e.offsetTop+e.offsetHeight-t.scrollTop>t.offsetHeight&&(t.scrollTop=e.offsetTop+e.offsetHeight-t.offsetHeight),e.offsetTop<t.scrollTop&&(t.scrollTop=e.offsetTop)};document.onkeydown=e=>{checkInInput=document.activeElement==inputSearch,"/"!==e.key||checkInInput||(e.stopPropagation(),e.preventDefault(),inputSearch.focus())},document.addEventListener("focusin",(e=>{divNavSearch.contains(e.target)||(divRes.style.display="none")})),inputSearch.onkeydown=e=>{if("Enter"===e.key){e.stopPropagation(),e.preventDefault();var t=ulRes.querySelector('li[class*="selected"]');window.location.href=t.getElementsByClassName("item__content")[0].firstChild.firstChild.href}"Escape"===e.key&&(divRes.style.display="none",inputSearch.blur())},divNavSearch.onkeydown=e=>{if(hasResult=ulRes.getElementsByTagName("li").length>=1,hasResult){["ArrowUp","ArrowDown"].indexOf(e.key)>-1&&e.preventDefault();var t=ulRes.firstChild,n=ulRes.lastChild,s=ulRes.querySelector('li[class*="selected"]');switch(e.key){case"ArrowUp":nextLi=s&&s!=t?s.previousSibling:n,addSelected(nextLi),s=nextLi,updateScroll(s,divRes);break;case"ArrowDown":nextLi=s&&s!=n?s.nextSibling:t,addSelected(nextLi),s=nextLi,updateScroll(s,divRes)}}};</script><div class=header-container><div class="header-logo post-layout"><img alt="Docker + GPUs" class=keep-original src=/img/header/docker.svg height=55 width=55></div><h1>Docker + GPUs</h1><div id=more-info><div id=note-tag><a href=/tags/mlops/ id=category }>MLOps</a> <a href=/tags/docker/ id=category }>Docker</a> <a href=/tags/backend/ id=category }>Backend</a></div><div id=last-modified>Last modified 15 days ago / <a href=https://github.com/dinhanhthi/notes/edit/master/./posts/mlops/2020-10-22-docker-gpu.md>Edit on Github</a></div></div></div></header><main class="" id=main-wrapper><article class=post-container><div class="container mt-2 normal page-note"><div class="toc toc-common toc-js"><div class=ol-container><div class=toc-heading>In this note</div><ol><li><a href=#wsl-%2B-windows>WSL + Windows</a><li><a href=#with-tensorflow-or-pytorch>With Tensorflow or PyTorch</a><li><a href=#basic-installation>Basic installation</a><li><a href=#check-info>Check info</a><ol><li><a href=#check-docker-work-with-gpu%3F>Check docker work with gpu?</a></ol><li><a href=#install-nvidia-docker2>Install nvidia-docker2</a><li><a href=#difference%3A-nvidia-container-toolkit-vs-nvidia-container-runtime>Difference: nvidia-container-toolkit vs nvidia-container-runtime</a><li><a href=#using-docker-compose%3F>Using docker-compose?</a><li><a href=#check-usage-of-gpu>Check usage of GPU</a><ol><li><a href=#kill-process>Kill process</a></ol><li><a href=#reset-gpu>Reset GPU</a><li><a href=#errors-with-gpu>Errors with GPU</a><li><a href=#make-nvidia-work-in-docker-(linux)>Make NVIDIA work in docker (Linux)</a><li><a href=#references>References</a></ol></div></div><p>ðŸ‘‰ Note: <a href=/docker/ >Docker 101</a><br>ðŸ‘‰ Note: <a href=/wordpress-docker/ >Wordpress Docker</a><br>ðŸ‘‰ Note: <a href=/airflow-k8s-101/ >Airflow + Kubernetes 101</a><br>ðŸ‘‰ Note: <a href=/tensorflow/ >Tensorflow extra</a><h2 id=wsl-%2B-windows tabindex=-1>WSL + Windows <a href=#wsl-%2B-windows class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h2><p>ðŸ‘‰ Note: <a href=/docker-wsl2-windows/#wsl-%2B-windows>WSL + Windows</a><h2 id=with-tensorflow-or-pytorch tabindex=-1>With Tensorflow or PyTorch <a href=#with-tensorflow-or-pytorch class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h2><p>ðŸ‘‰ <a href=https://www.tensorflow.org/install/docker>Official doc for TF + docker</a><br>ðŸ‘‰ Note: <a href=/tensorflow#installation-with-docker>Docker + TF</a>.<br>ðŸ‘‰ <a href=https://github.com/dinhanhthi/git_dataswati/tree/master/docker-thi>An example of docker pytorch with gpu support</a>.<h2 id=basic-installation tabindex=-1>Basic installation <a href=#basic-installation class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h2><div class=warning><p>You have to install (successfully) GPU driver on your (linux) machine before continuing the steps in this note. Go to "<a href=#check-info>Check info</a>" section to check the availability of your drivers.</div><div class=info><p>(Maybe <strong>for me only</strong>) It works perfectly on <strong>Pop!_OS 20.04</strong>, I've tried and we have many problems with <strong>Pop!_OS 21.10</strong>. Therefore <mark>stick to 20.04</mark>!!!!</div><pre class=language-bash><code class=language-bash><span class="token function">sudo</span> <span class="token function">apt</span> update<br><br><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> -y nvidia-container-runtime<br><span class="token comment"># You may need to replace above line with</span><br><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> nvidia-docker2<br><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> nvidia-container-toolkit<br><br><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> -y nvidia-cuda-toolkit<br><span class="token comment"># restard required</span></code></pre><p>If you have problems when installing <code>nvidia-docker2</code>, read <a href=/docker-gpu/#install-nvidia-docker2>this section</a>!<h2 id=check-info tabindex=-1>Check info <a href=#check-info class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h2><pre class=language-bash><code class=language-bash><span class="token comment"># verify that your computer has a graphic card</span><br>lspci -nn <span class="token operator">|</span> <span class="token function">grep</span> <span class="token string">'\[03'</span></code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># First, install drivers and check</span><br>nvidia-smi<br><span class="token comment"># output: NVIDIA-SMI 450.80.02 Driver Version: 450.80.02    CUDA Version: 11.0</span><br><span class="token comment"># it's maximum CUDA version that your driver supports</span></code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># check current version of cuda</span><br>nvcc --version<br><span class="token comment"># If there is not nvcc, it may be in /usr/local/cuda/bin/</span><br><span class="token comment"># Add this location to PATH</span><br><span class="token comment"># modify ~/.zshrc or ~/.bashrc</span><br><span class="token builtin class-name">export</span> <span class="token variable assign-left"><span class="token constant environment">PATH</span></span><span class="token operator">=</span>/usr/local/cuda/bin:<span class="token constant environment">$PATH</span><br><br><span class="token comment"># You may need to install</span><br><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> -y nvidia-cuda-toolkit</code></pre><p>If below command doesn't work, try to install <code>nvidia-docker2</code> (read <a href=#install-nvidia-docker2>this section</a>).<pre class=language-bash><code class=language-bash><span class="token comment"># install and check nvidia-docker</span><br>dpkg -l <span class="token operator">|</span> <span class="token function">grep</span> nvidia-docker<br><span class="token comment"># or</span><br>nvidia-docker version</code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># Verifying â€“gpus option under docker run</span><br><span class="token function">docker</span> run --help <span class="token operator">|</span> <span class="token function">grep</span> -i gpus<br><span class="token comment"># output: --gpus gpu-request GPU devices to add to the container ('all' to pass all GPUs)</span></code></pre><h3 id=check-docker-work-with-gpu%3F tabindex=-1>Check docker work with gpu? <a href=#check-docker-work-with-gpu%3F class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h3><pre class=language-bash><code class=language-bash><span class="token comment"># Listing out GPU devices</span><br><span class="token function">docker</span> run -it --rm --gpus all ubuntu nvidia-smi -L<br><span class="token comment"># output: GPU 0: GeForce GTX 1650 (...)</span></code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># ERROR ?</span><br><span class="token comment"># docker: Error response from daemon: failed to create shim: OCI runtime create failed: container_linux.go:380: starting container process caused: process_linux.go:545: container init caused: Running hook #0:: error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: initialization error: load library failed: libnvidia-ml.so.1: cannot open shared object file: no such file or directory: unknown.</span></code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># ERROR ?</span><br><span class="token comment"># Error response from daemon: could not select device driver "" with capabilities: [[gpu]]</span><br><br><span class="token comment"># Solution: install nvidia-docker2</span></code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># Verifying again with nvidia-smi</span><br><span class="token function">docker</span> run -it --rm --gpus all ubuntu nvidia-smi<br><br><span class="token comment"># Return something like</span><br>+-----------------------------------------------------------------------------+<br><span class="token operator">|</span> NVIDIA-SMI <span class="token number">510.54</span>       Driver Version: <span class="token number">510.54</span>       CUDA Version: <span class="token number">11.6</span>     <span class="token operator">|</span><br><span class="token operator">|</span>-------------------------------+----------------------+----------------------+<br><span class="token operator">|</span> GPU  Name        Persistence-M<span class="token operator">|</span> Bus-Id        Disp.A <span class="token operator">|</span> Volatile Uncorr. ECC <span class="token operator">|</span><br><span class="token operator">|</span> Fan  Temp  Perf  Pwr:Usage/Cap<span class="token operator">|</span>         Memory-Usage <span class="token operator">|</span> GPU-Util  Compute M. <span class="token operator">|</span><br><span class="token operator">|</span>                               <span class="token operator">|</span>                      <span class="token operator">|</span>               MIG M. <span class="token operator">|</span><br><span class="token operator">|</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span><span class="token operator">+=</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span><span class="token operator">+=</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span><span class="token operator">|</span><br><span class="token operator">|</span>   <span class="token number">0</span>  NVIDIA GeForce <span class="token punctuation">..</span>.  Off  <span class="token operator">|</span> 00000000:01:00.0 Off <span class="token operator">|</span>                  N/A <span class="token operator">|</span><br><span class="token operator">|</span> N/A   55C    P0    11W /  N/A <span class="token operator">|</span>    369MiB /  4096MiB <span class="token operator">|</span>      <span class="token number">5</span>%      Default <span class="token operator">|</span><br><span class="token operator">|</span>                               <span class="token operator">|</span>                      <span class="token operator">|</span>                  N/A <span class="token operator">|</span><br>+-------------------------------+----------------------+----------------------+<br><span class="token comment"># and another box like this</span></code></pre><div class=hsbox><div class=hs__title>Archived but still useful</div><div class=hs__content><pre class=language-bash><code class=language-bash><span class="token comment"># Test a working setup container-toolkit</span><br><span class="token comment"># Update 14/04/2022: the tag "latest" has deprecated => check your system versions and use</span><br><span class="token comment"># the corresponding tag</span><br><span class="token comment"># So, the below code is only for reference, it's not working anymore</span><br><span class="token function">docker</span> run --rm --gpus all nvidia/cuda nvidia-smi</code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># Test a working setup container-runtime</span><br><span class="token comment"># Update 14/04/2022: below code isn't working anymore because nvidia/cuda doesn't have</span><br><span class="token comment"># the "latest" tag!</span><br><span class="token function">docker</span> run --runtime<span class="token operator">=</span>nvidia --rm nvidia/cuda nvidia-smi<br><br><span class="token comment"># Error response from daemon: Unknown runtime specified nvidia.</span><br><span class="token comment"># Search below for "/etc/docker/daemon.json"</span><br><span class="token comment"># Maybe it helps.</span></code></pre></div></div><h2 id=install-nvidia-docker2 tabindex=-1>Install <code>nvidia-docker2</code> <a href=#install-nvidia-docker2 class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h2><div class=hsbox><div class=hs__title>More information (<a href=https://github.com/NVIDIA/nvidia-docker/issues/1268>ref</a>)</div><div class=hs__content><blockquote><p>This package is the only docker-specific package of any of them. It takes the script associated with the <code>nvidia-container-runtime</code> and installs it into docker's <code>/etc/docker/daemon.json</code> file for you. This then allows you to run (for example) <code>docker run --runtime=nvidia ...</code> to automatically add GPU support to your containers. It also installs a wrapper script around the native docker CLI called <code>nvidia-docker</code> which lets you invoke docker without needing to specify <code>--runtime=nvidia</code> every single time. It also lets you set an environment variable on the host (NV_GPU) to specify which GPUs should be injected into a container.</blockquote></div></div><p>ðŸ‘‰ (Should follow this for the up-to-date) <a href=https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker>Officicial guide to install</a>.<p><strong>Note</strong>: (For me only) use below codes.<div class=hsbox><div class=hs__title>Command lines (for quickly preview)</div><div class=hs__content><pre class=language-bash><code class=language-bash><span class="token variable assign-left">distribution</span><span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span><span class="token builtin class-name">.</span> /etc/os-release<span class="token punctuation">;</span><span class="token builtin class-name">echo</span> $ID$VERSION_ID<span class="token variable">)</span></span><br><br><span class="token comment"># NOTE FOR POPOS 20.04</span><br><span class="token comment"># replace above line with</span><br><span class="token variable assign-left">distribution</span><span class="token operator">=</span>ubuntu20.04<br><br><span class="token function">curl</span> -s -L https://nvidia.github.io/nvidia-docker/gpgkey <span class="token operator">|</span> <span class="token function">sudo</span> apt-key <span class="token function">add</span> -<br><span class="token function">curl</span> -s -L https://nvidia.github.io/nvidia-docker/<span class="token variable">$distribution</span>/nvidia-docker.list <span class="token operator">|</span> <span class="token function">sudo</span> <span class="token function">tee</span> /etc/apt/sources.list.d/nvidia-docker.list<br><br><span class="token function">sudo</span> <span class="token function">apt-get</span> update<br><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> -y nvidia-docker2</code></pre><p>ðŸ‘‡ Read more about <a href=https://gist.github.com/kuang-da/2796a792ced96deaf466fdfb7651aa2e#install-nvidia-docker2>below error</a>.<pre class=language-bash><code class=language-bash><span class="token comment"># Error?</span><br><span class="token comment"># Read more: </span><br><span class="token comment"># Depends: nvidia-container-toolkit (>= 1.9.0-1) but 1.5.1-1pop1~1627998766~20.04~9847cf2 is to be installed</span><br><br><span class="token comment"># create a new file</span><br><span class="token function">sudo</span> <span class="token function">nano</span> /etc/apt/preferences.d/nvidia-docker-pin-1002<br><span class="token comment"># with below content</span><br>Package: *<br>Pin: origin nvidia.github.io<br>Pin-Priority: <span class="token number">1002</span><br><span class="token comment"># then save</span><br><br><span class="token comment"># try again</span><br><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> -y nvidia-docker2</code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># restart docker</span><br><span class="token function">sudo</span> systemctl restart <span class="token function">docker</span><br><br><span class="token comment"># wanna check?</span><br><span class="token function">sudo</span> <span class="token function">docker</span> run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi</code></pre></div></div><pre class=language-bash><code class=language-bash><span class="token comment"># check version</span><br>nvidia-docker version</code></pre><h2 id=difference%3A-nvidia-container-toolkit-vs-nvidia-container-runtime tabindex=-1>Difference: <code>nvidia-container-toolkit</code> vs <code>nvidia-container-runtime</code> <a href=#difference%3A-nvidia-container-toolkit-vs-nvidia-container-runtime class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h2><p>ðŸ‘‰ <a href=https://github.com/NVIDIA/nvidia-docker/issues/1268>What's the difference between the lastest nvidia-docker and nvidia container runtimeï¼Ÿ</a><blockquote><p>In this note, with Docker 19.03+ (<code>docker --version</code>), he says that <code>nvidia-container-toolkit</code> is used for <code>--gpus</code> (in <code>docker run ...</code>), <code>nvidia-container-runtime</code> is used for <code>--runtime=nvidia</code> (can also be used in <code>docker-compose</code> file).</blockquote><blockquote><p>However, <mark markdown=span>if you want to use Kubernetes with Docker 19.03, you actually <strong>need to continue using nvidia-docker2</strong></mark> because Kubernetes doesn't support passing GPU information down to docker through the <code>--gpus</code> flag yet. It still relies on the nvidia-container-runtime to pass GPU information down the stack via a set of environment variables.</blockquote><p>ðŸ‘‰ <a href=https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker>Installation Guide â€” NVIDIA Cloud Native Technologies documentation</a><h2 id=using-docker-compose%3F tabindex=-1>Using docker-compose? <a href=#using-docker-compose%3F class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h2><p>Purpose?<div class=col-2-equal><pre class=language-bash><code class=language-bash><span class="token comment"># instead of using</span><br><span class="token function">docker</span> run <span class="token punctuation">\</span><br>    --gpus all<span class="token punctuation">\</span><br>    --name docker_thi_test<span class="token punctuation">\</span><br>    --rm<span class="token punctuation">\</span><br>    -v abc:abc<span class="token punctuation">\</span><br>    -p <span class="token number">8888</span>:8888</code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># we use this with docker-compose.yml</span><br><span class="token function">docker-compose</span> up</code></pre></div><pre class=language-bash><code class=language-bash><span class="token comment"># check version of docker-compose</span><br><span class="token function">docker-compose</span> --version</code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># If "version" in docker-compose.yml &lt; 2.3</span><br><span class="token comment"># Modify: /etc/docker/daemon.json</span><br><span class="token punctuation">{</span><br>    <span class="token string">"default-runtime"</span><span class="token builtin class-name">:</span> <span class="token string">"nvidia"</span>,<br>    <span class="token string">"runtimes"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><br>        <span class="token string">"nvidia"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><br>            <span class="token string">"path"</span><span class="token builtin class-name">:</span> <span class="token string">"nvidia-container-runtime"</span>,<br>            <span class="token string">"runtimeArgs"</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><br>        <span class="token punctuation">}</span><br>    <span class="token punctuation">}</span><br><span class="token punctuation">}</span></code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># restart our docker daemon</span><br><span class="token function">sudo</span> <span class="token function">pkill</span> -SIGHUP dockerd</code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># If "version" in docker-compose.yml >=2.3</span><br><span class="token comment"># docker-compose.yml => able to use "runtime"</span><br>version: <span class="token string">'2.3'</span> <span class="token comment"># MUST BE >=2.3 AND &lt;3</span><br>services:<br>  testing:<br>    ports:<br>      - <span class="token string">"8000:8000"</span><br>    runtime: nvidia<br>    volumes:<br>      - ./object_detection:/object_detection</code></pre><p>ðŸ‘‰ Check more in my repo <a href=https://github.com/dinhanhthi/my-dockerfiles>my-dockerfiles</a> on Github.<p>Run the test,<pre class=language-bash><code class=language-bash><span class="token function">docker</span> pull tensorflow/tensorflow:latest-gpu-jupyter<br><span class="token function">mkdir</span> ~/Downloads/test/notebooks</code></pre><p>Without using <code>docker-compose.yml</code> (tensorflow) (cf. <a href=/tensorflow#without-docker-compose>this note</a> for more)<pre class=language-bash><code class=language-bash><span class="token function">docker</span> run --name docker_thi_test -it --rm -v <span class="token variable"><span class="token variable">$(</span>realpath ~/Downloads/test/notebooks<span class="token variable">)</span></span>:/tf/notebooks -p <span class="token number">8888</span>:8888 tensorflow/tensorflow:latest-gpu-jupyter</code></pre><p>With <code>docker-compose.yml</code>?<pre class=language-bash><code class=language-bash><span class="token comment"># ~/Download/test/Dockerfile</span><br>FROM tensorflow/tensorflow:latest-gpu-jupyter</code></pre><pre class=language-yaml><code class=language-yaml><span class="token comment"># ~/Download/test/docker-compose.yml</span><br><span class="token atrule key">version</span><span class="token punctuation">:</span> <span class="token string">'2'</span><br><span class="token atrule key">services</span><span class="token punctuation">:</span><br>  <span class="token atrule key">jupyter</span><span class="token punctuation">:</span><br>    <span class="token atrule key">container_name</span><span class="token punctuation">:</span> <span class="token string">'docker_thi_test'</span><br>    <span class="token atrule key">build</span><span class="token punctuation">:</span> .<br>    <span class="token atrule key">volumes</span><span class="token punctuation">:</span><br>        <span class="token punctuation">-</span> ./notebooks<span class="token punctuation">:</span>/tf/notebooks <span class="token comment"># notebook directory</span><br>    <span class="token atrule key">ports</span><span class="token punctuation">:</span><br>        <span class="token punctuation">-</span> 8888<span class="token punctuation">:</span><span class="token number">8888</span> <span class="token comment"># exposed port for jupyter</span><br>    <span class="token atrule key">environment</span><span class="token punctuation">:</span><br>        <span class="token punctuation">-</span> NVIDIA_VISIBLE_DEVICES=0 <span class="token comment"># which gpu do you want to use for this container</span><br>        <span class="token punctuation">-</span> PASSWORD=12345</code></pre><p>Then run,<pre class=language-bash><code class=language-bash><span class="token function">docker-compose</span> run --rm jupyter</code></pre><h2 id=check-usage-of-gpu tabindex=-1>Check usage of GPU <a href=#check-usage-of-gpu class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h2><pre class=language-bash><code class=language-bash><span class="token comment"># Linux only</span><br>nvidia-smi</code></pre><div class=hsbox><div class=hs__title>Return something like this</div><div class=hs__content><pre class=language-bash><code class=language-bash><span class="token comment"># |===============================+======================+======================|</span><br><span class="token comment"># |   0  GeForce GTX 1650    Off  | 00000000:01:00.0 Off |                  N/A |</span><br><span class="token comment"># | N/A   53C    P8     2W /  N/A |   3861MiB /  3914MiB |      2%      Default |</span><br><span class="token comment"># |                               |                      |                  N/A |</span><br><span class="token comment"># +-------------------------------+----------------------+----------------------+</span><br><br><span class="token comment"># => 3861MB / 3914MB is used!</span><br><br><span class="token comment"># +-----------------------------------------------------------------------------+</span><br><span class="token comment"># | Processes:                                                       GPU Memory |</span><br><span class="token comment"># |  GPU       PID   Type   Process name                             Usage      |</span><br><span class="token comment"># |=============================================================================|</span><br><span class="token comment"># |    0      3019      C   ...e/scarter/anaconda3/envs/tf1/bin/python  3812MiB |</span><br><span class="token comment"># +-----------------------------------------------------------------------------+</span><br><br><span class="token comment"># => Process 3019 is using the GPU</span></code></pre></div></div><pre class=language-bash><code class=language-bash><span class="token comment"># All processes that use GPU</span><br><span class="token function">sudo</span> <span class="token function">fuser</span> -v /dev/nvidia*</code></pre><h3 id=kill-process tabindex=-1>Kill process <a href=#kill-process class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h3><pre class=language-bash><code class=language-bash><span class="token comment"># Kill a single process</span><br><span class="token function">sudo</span> <span class="token function">kill</span> -9 <span class="token number">3019</span></code></pre><h2 id=reset-gpu tabindex=-1>Reset GPU <a href=#reset-gpu class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h2><div class=col-2-equal><pre class=language-bash><code class=language-bash><span class="token comment"># all</span><br><span class="token function">sudo</span> nvidia-smi --gpu-reset</code></pre><pre class=language-bash><code class=language-bash><span class="token comment"># single</span><br><span class="token function">sudo</span> nvidia-smi --gpu-reset -i <span class="token number">0</span></code></pre></div><h2 id=errors-with-gpu tabindex=-1>Errors with GPU <a href=#errors-with-gpu class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h2><pre class=language-bash><code class=language-bash><span class="token comment"># Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.</span><br><span class="token comment"># Function call stack:</span><br><span class="token comment"># train_function</span></code></pre><p>Check <a href=https://stackoverflow.com/a/56511889/1323473>this answer</a> as a reference!<hr><p>Problems with pytorch versions: <a href=/pytorch#errors>check this</a>.<hr><p><em>RuntimeError: cuda runtime error (804) : forward compatibility was attempted on non supported HW at /pytorch/aten/src/THC/THCGeneral.cpp:47</em> (after update system including nvdia-cli, maybe) => The same problem with below, need to restart the computer.<hr><p><code>nvidia-smi</code>: <em>Failed to initialize NVML: Driver/library version mismatch</em>.<p><a href=https://stackoverflow.com/questions/43022843/nvidia-nvml-driver-library-version-mismatch>This thread</a>: just restart the computer.<h2 id=make-nvidia-work-in-docker-(linux) tabindex=-1>Make NVIDIA work in docker (Linux) <a href=#make-nvidia-work-in-docker-(linux) class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h2><div class=danger><p>This section is still working (on 26-Oct-2020) but it's old for newer methods.</div><p><strong>Idea</strong>: Using NVIDIA driver of the base machine, don't install anything in docker!<div class=hsbox><div class=hs__title>Detail of steps</div><div class=hs__content><p class=noindent><ol><li><p>First, <a href=/pytorch#installation>maker sure</a> your base machine has an NVIDIA driver.<pre class=language-bash><code class=language-bash><span class="token comment"># list all gpus</span><br>lspci -nn <span class="token operator">|</span> <span class="token function">grep</span> <span class="token string">'\[03'</span><br><br><span class="token comment"># check nvidia & cuda versions</span><br>nvidia-smi</code></pre><li><p>Install <a href=https://github.com/NVIDIA/nvidia-container-runtime><code>nvidia-container-runtime</code></a><pre class=language-bash><code class=language-bash><span class="token function">curl</span> -s -L https://nvidia.github.io/nvidia-container-runtime/gpgkey <span class="token operator">|</span> <span class="token function">sudo</span> apt-key <span class="token function">add</span> -<br><span class="token variable assign-left">distribution</span><span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span><span class="token builtin class-name">.</span> /etc/os-release<span class="token punctuation">;</span><span class="token builtin class-name">echo</span> $ID$VERSION_ID<span class="token variable">)</span></span><br><br><span class="token function">curl</span> -s -L https://nvidia.github.io/nvidia-container-runtime/<span class="token variable">$distribution</span>/nvidia-container-runtime.list <span class="token operator">|</span> <span class="token function">sudo</span> <span class="token function">tee</span> /etc/apt/sources.list.d/nvidia-container-runtime.list<br><br><span class="token function">sudo</span> <span class="token function">apt-get</span> update<br><br><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> nvidia-container-runtime</code></pre><li><p>Note that, <mark markdown=span>we cannot use <code>docker-compose.yml</code> in this case!!!</mark><li><p>Create an image <code>img_datas</code> with <code>Dockerfile</code> is<pre class=language-docker><code class=language-docker><span class="token instruction"><span class="token keyword">FROM</span> nvidia/cuda:10.2-base</span><br><br><span class="token instruction"><span class="token keyword">RUN</span> apt-get update && <span class="token operator">\</span><br>	apt-get -y upgrade && <span class="token operator">\</span><br>	apt-get install -y python3-pip python3-dev locales git</span><br><br><span class="token comment"># install dependencies</span><br><span class="token instruction"><span class="token keyword">COPY</span> requirements.txt requirements.txt</span><br><span class="token instruction"><span class="token keyword">RUN</span> python3 -m pip install --upgrade pip && <span class="token operator">\</span><br>	python3 -m pip install -r requirements.txt</span><br><span class="token instruction"><span class="token keyword">COPY</span> . .</span><br><br><span class="token comment"># default command</span><br><span class="token instruction"><span class="token keyword">CMD</span> [ <span class="token string">"jupyter"</span>, <span class="token string">"lab"</span>, <span class="token string">"--no-browser"</span>, <span class="token string">"--allow-root"</span>, <span class="token string">"--ip=0.0.0.0"</span>  ]</span></code></pre><li><p>Create a container,<pre class=language-bash><code class=language-bash><span class="token function">docker</span> run --name docker_thi --gpus all -v /home/thi/folder_1/:/srv/folder_1/ -v /home/thi/folder_1/git/:/srv/folder_2 -dp <span class="token number">8888</span>:8888 -w<span class="token operator">=</span><span class="token string">"/srv"</span> -it img_datas<br><br><span class="token comment"># -v: volumes</span><br><span class="token comment"># -w: working dir</span><br><span class="token comment"># --gpus all: using all gpus on base machine</span></code></pre></ol><p><a href=https://towardsdatascience.com/how-to-properly-use-the-gpu-within-a-docker-container-4c699c78c6d1>This article</a> is also very interesting and helpful in some cases.</div></div><h2 id=references tabindex=-1>References <a href=#references class=direct-link aria-hidden=true><i class="fontello-icon icon-link"></i></a></h2><ol><li><a href=https://github.com/NVIDIA/nvidia-docker/wiki/CUDA>Difference between <code>base</code>, <code>runtime</code> and <code>devel</code> in <code>Dockerfile</code> of CUDA</a>.<li><a href=https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/dockerfiles/dockerfiles>Dockerfile on Github</a> of Tensorflow.</ol></div><script type=application/ld+json>{
        "@context": "https://schema.org",
        "@type": "Article",
        "headline": "Docker + GPUs",
        "image": [],
        "author": "Anh-Thi DINH",
        "url": "https://dinhanhthi.com/docker-gpu/",
        "mainEntityOfPage": "https://dinhanhthi.com/docker-gpu/",
        "datePublished": "21-04-2022",
        "dateModified": "2022-04-21",
        "description": "ðŸ‘‰ Note: Docker 101 ðŸ‘‰ Note: Wordpress Docker ðŸ‘‰ Note: Airflow + Kubernetes 101 ðŸ‘‰ Note: Tensorflow extra WSL + Windows ðŸ‘‰ Note: WSL +..."
      }</script></article></main><footer><a href=/ target=_blank>Thi Â Â©Â  2022 </a>Â â€¢Â  <a href=/about-the-notes/ >About this site </a>Â â€¢Â  <a href=https://photos.app.goo.gl/9OVEkdTjmtRPg7vC3 target=_blank>My sketches </a>Â â€¢Â  <a href=https://goo.gl/photos/yQXdQws1LLS16x5v5 target=_blank>I cook </a>Â â€¢Â  <a href=/support-thi/ ><img alt="Support Thi" class=keep-original src=/img_src/icons/coffee.svg height=16 width=auto> Support Thi</a></footer><script src=https://cdnjs.cloudflare.com/ajax/libs/elasticlunr/0.9.6/elasticlunr.min.js></script><script src=/src/js/components/clipboard.min.js></script><script src="/src/js/main.min.js?hash=d3b51a19b7" async defer></script><a href=/support-thi/ class="floating-button tooltip" id=buy-me-a-coffee><img alt="Support Thi" class=keep-original src=/img_src/icons/coffee.svg> <span class=tooltiptext>Support Thi</span> </a><button class="floating-button tooltip" id=scroll-top-btn><img alt="Scroll to top" class=keep-original src=/img_src/to-top.webp> <span class=tooltiptext>Top</span></button>